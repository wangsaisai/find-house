import os
import json
import asyncio
import google.generativeai as genai
from typing import Dict, List, Any, Optional
import logging
from dotenv import load_dotenv
import aiohttp

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½® Google Gemini API
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("No GOOGLE_API_KEY found in environment variables.")
genai.configure(api_key=GEMINI_API_KEY)

# é«˜å¾·åœ°å›¾ MCP æœåŠ¡å™¨é…ç½®
AMAP_MCP_KEY = os.getenv("AMAP_MCP_KEY")
AMAP_MCP_URL = f"https://mcp.amap.com/mcp?key={AMAP_MCP_KEY}"

class MCPToolManager:
    """MCPå·¥å…·ç®¡ç†å™¨ï¼Œè´Ÿè´£ä¸MCPæœåŠ¡å™¨é€šä¿¡"""
    
    def __init__(self, url: str):
        self.url = url
        self.session = None
        self.request_id = 0
        self.available_tools = {}
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        await self.initialize()
        await self.load_available_tools()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def _next_id(self):
        self.request_id += 1
        return self.request_id
    
    async def initialize(self):
        """åˆå§‹åŒ– MCP è¿æ¥"""
        payload = {
            "jsonrpc": "2.0",
            "id": self._next_id(),
            "method": "initialize",
            "params": {
                "protocolVersion": "2024-11-05",
                "capabilities": {"tools": {}},
                "clientInfo": {
                    "name": "intelligent-rental-analyzer",
                    "version": "1.0.0"
                }
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }
        
        async with self.session.post(self.url, json=payload, headers=headers) as response:
            if response.status != 200:
                raise Exception("MCP initialization failed")
            result = await response.json()
            return result
    
    async def load_available_tools(self):
        """åŠ è½½å¯ç”¨å·¥å…·åˆ—è¡¨å¹¶æ„å»ºå·¥å…·æè¿°"""
        payload = {
            "jsonrpc": "2.0",
            "id": self._next_id(),
            "method": "tools/list",
            "params": {}
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }
        
        async with self.session.post(self.url, json=payload, headers=headers) as response:
            if response.status == 200:
                result = await response.json()
                if "result" in result and "tools" in result["result"]:
                    for tool in result["result"]["tools"]:
                        self.available_tools[tool["name"]] = tool
                        logger.info(f"Loaded tool: {tool['name']}")
    
    async def call_tool(self, tool_name: str, arguments: dict):
        """è°ƒç”¨æŒ‡å®šçš„MCPå·¥å…·"""
        payload = {
            "jsonrpc": "2.0",
            "id": self._next_id(),
            "method": "tools/call",
            "params": {
                "name": tool_name,
                "arguments": arguments
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }
        
        logger.info(f"Calling tool {tool_name} with arguments: {arguments}")
        async with self.session.post(self.url, json=payload, headers=headers) as response:
            if response.status != 200:
                text = await response.text()
                logger.error(f"Failed to call tool {tool_name}: {text}")
                return {"error": f"Failed to call tool {tool_name}"}
            result = await response.json()
            logger.info(f"Tool {tool_name} result received")
            return result
    
    def get_tools_description(self) -> str:
        """ç”Ÿæˆå·¥å…·æè¿°ï¼Œä¾›LLMç†è§£å¯ç”¨å·¥å…·"""
        descriptions = []
        for tool_name, tool_info in self.available_tools.items():
            desc = f"**{tool_name}**: {tool_info.get('description', 'æ— æè¿°')}"
            if 'inputSchema' in tool_info:
                schema = tool_info['inputSchema']
                if 'properties' in schema:
                    params = []
                    for param_name, param_info in schema['properties'].items():
                        param_desc = f"{param_name} ({param_info.get('type', 'unknown')})"
                        if param_info.get('description'):
                            param_desc += f": {param_info['description']}"
                        params.append(param_desc)
                    desc += f"\n  å‚æ•°: {', '.join(params)}"
            descriptions.append(desc)
        return "\n\n".join(descriptions)

class IntelligentRentalAnalyzer:
    """æ™ºèƒ½ç§Ÿæˆ¿ä½ç½®åˆ†æå™¨ï¼Œä½¿ç”¨LLMæ¨ç†èƒ½åŠ›æ™ºèƒ½è°ƒç”¨MCPå·¥å…·"""
    
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-2.5-pro')
        self.conversation_history = []
        self.analysis_data = {}
    
    async def analyze_rental_locations(self, work_address1: str, work_address2: str, 
                                     budget_range: str = "ä¸é™", preferences: str = "") -> Dict[str, Any]:
        """ä½¿ç”¨LLMæ¨ç†èƒ½åŠ›è¿›è¡Œæ™ºèƒ½ç§Ÿæˆ¿åˆ†æ"""
        
        async with MCPToolManager(AMAP_MCP_URL) as tool_manager:
            # ç¬¬ä¸€æ­¥ï¼šè®©LLMç†è§£ä»»åŠ¡å¹¶åˆ¶å®šåˆ†æè®¡åˆ’
            initial_prompt = f"""
            æˆ‘æ˜¯ä¸€ä¸ªæ™ºèƒ½ç§Ÿæˆ¿ä½ç½®åˆ†æåŠ©æ‰‹ã€‚ç°åœ¨éœ€è¦ä¸ºç”¨æˆ·æ‰¾åˆ°æœ€ä½³ç§Ÿæˆ¿ä½ç½®ã€‚

            **ç”¨æˆ·éœ€æ±‚ï¼š**
            - å·¥ä½œåœ°ç‚¹A: {work_address1}
            - å·¥ä½œåœ°ç‚¹B: {work_address2}  
            - é¢„ç®—èŒƒå›´: {budget_range}
            - ç‰¹æ®Šåå¥½: {preferences if preferences else "æ— "}

            **å¯ç”¨çš„åœ°å›¾APIå·¥å…·ï¼š**
            {tool_manager.get_tools_description()}

            è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œåˆ¶å®šä¸€ä¸ªè¯¦ç»†çš„åˆ†æè®¡åˆ’ã€‚ä½ éœ€è¦ï¼š
            1. åˆ†æéœ€è¦æ”¶é›†å“ªäº›ä¿¡æ¯
            2. ç¡®å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·åŠå…¶è°ƒç”¨é¡ºåº
            3. è¯´æ˜æ¯ä¸ªå·¥å…·è°ƒç”¨çš„ç›®çš„å’ŒæœŸæœ›ç»“æœ

            è¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
            ## åˆ†æè®¡åˆ’
            
            ### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ä¿¡æ¯æ”¶é›†
            - å·¥å…·åç§°ï¼šxxx
            - è°ƒç”¨ç›®çš„ï¼šxxx
            - é¢„æœŸç»“æœï¼šxxx
            
            ### ç¬¬äºŒé˜¶æ®µï¼šxxx
            ...
            
            è¯·å¼€å§‹åˆ¶å®šåˆ†æè®¡åˆ’ã€‚
            """
            
            # è·å–LLMçš„åˆ†æè®¡åˆ’
            plan_response = self.model.generate_content(initial_prompt)
            analysis_plan = plan_response.text
            self.conversation_history.append(("plan", analysis_plan))
            logger.info(f"LLMåˆ¶å®šçš„åˆ†æè®¡åˆ’:\n{analysis_plan}")
            
            # ç¬¬äºŒæ­¥ï¼šæ ¹æ®è®¡åˆ’é€æ­¥æ‰§è¡Œåˆ†æ
            return await self._execute_analysis_with_llm_guidance(
                tool_manager, work_address1, work_address2, budget_range, preferences
            )
    
    async def _execute_analysis_with_llm_guidance(self, tool_manager: MCPToolManager, 
                                                  work_address1: str, work_address2: str,
                                                  budget_range: str, preferences: str) -> Dict[str, Any]:
        """åœ¨LLMæŒ‡å¯¼ä¸‹æ‰§è¡Œåˆ†æ"""
        
        analysis_results = {
            "work_address1": work_address1,
            "work_address2": work_address2,
            "budget_range": budget_range,
            "preferences": preferences,
            "tool_calls": [],
            "coordinates": {},
            "analysis_data": {}
        }
        
        max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯
        iteration = 0
        
        while iteration < max_iterations:
            iteration += 1
            
            # è¯¢é—®LLMä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
            current_status = self._generate_current_status(analysis_results)
            
            next_step_prompt = f"""
            å½“å‰åˆ†æçŠ¶æ€ï¼š
            {current_status}
            
            **å·²æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ï¼š**
            {self._format_tool_calls_history(analysis_results["tool_calls"])}
            
            **å¯ç”¨å·¥å…·ï¼š**
            {tool_manager.get_tools_description()}
            
            æ ¹æ®å½“å‰çŠ¶æ€ï¼Œè¯·å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š
            1. å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·ï¼Œè¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
               ```
               CALL_TOOL
               å·¥å…·åç§°: xxx
               å‚æ•°: {{"param1": "value1", "param2": "value2"}}
               åŸå› : xxx
               ```
            
            2. å¦‚æœä¿¡æ¯æ”¶é›†å®Œæ¯•ï¼Œå¯ä»¥è¿›è¡Œæœ€ç»ˆåˆ†æï¼Œè¯·å›ç­”ï¼š
               ```
               GENERATE_ANALYSIS
               åŸå› : xxx
               ```
            
            3. å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œè¯·å›ç­”ï¼š
               ```
               NEED_MORE_INFO
               éœ€è¦çš„ä¿¡æ¯: xxx
               å»ºè®®çš„å·¥å…·: xxx
               ```
            
            è¯·åˆ†æå½“å‰æƒ…å†µå¹¶ç»™å‡ºå†³ç­–ã€‚
            """
            
            llm_decision = self.model.generate_content(next_step_prompt)
            decision_text = llm_decision.text.strip()
            
            logger.info(f"LLMå†³ç­– (ç¬¬{iteration}è½®): {decision_text}")
            
            # è§£æLLMçš„å†³ç­–
            if "CALL_TOOL" in decision_text:
                # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
                tool_call_info = self._parse_tool_call_decision(decision_text)
                if tool_call_info:
                    tool_name = tool_call_info["tool_name"]
                    arguments = tool_call_info["arguments"]
                    reason = tool_call_info["reason"]
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    try:
                        result = await tool_manager.call_tool(tool_name, arguments)
                        analysis_results["tool_calls"].append({
                            "tool_name": tool_name,
                            "arguments": arguments,
                            "result": result,
                            "reason": reason,
                            "iteration": iteration
                        })
                        
                        # æ›´æ–°åˆ†ææ•°æ®
                        self._update_analysis_data(analysis_results, tool_name, result)
                        
                        logger.info(f"æˆåŠŸæ‰§è¡Œå·¥å…·è°ƒç”¨: {tool_name}")
                        
                    except Exception as e:
                        logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {tool_name}, é”™è¯¯: {e}")
                        analysis_results["tool_calls"].append({
                            "tool_name": tool_name,
                            "arguments": arguments,
                            "error": str(e),
                            "reason": reason,
                            "iteration": iteration
                        })
                
            elif "GENERATE_ANALYSIS" in decision_text:
                # ç”Ÿæˆæœ€ç»ˆåˆ†æ
                logger.info("LLMå†³å®šç”Ÿæˆæœ€ç»ˆåˆ†æ")
                final_analysis = await self._generate_final_analysis(analysis_results)
                analysis_results["final_analysis"] = final_analysis
                break
                
            elif "NEED_MORE_INFO" in decision_text:
                logger.info(f"LLMè¡¨ç¤ºéœ€è¦æ›´å¤šä¿¡æ¯: {decision_text}")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å¤„ç†é€»è¾‘
                
            else:
                logger.warning(f"æ— æ³•è§£æLLMå†³ç­–: {decision_text}")
                break
        
        return analysis_results
    
    def _parse_tool_call_decision(self, decision_text: str) -> Optional[Dict[str, Any]]:
        """è§£æLLMçš„å·¥å…·è°ƒç”¨å†³ç­–"""
        try:
            lines = decision_text.split('\n')
            tool_name = None
            arguments = {}
            reason = ""
            
            for line in lines:
                line = line.strip()
                if line.startswith('å·¥å…·åç§°:'):
                    tool_name = line.split(':', 1)[1].strip()
                elif line.startswith('å‚æ•°:'):
                    param_str = line.split(':', 1)[1].strip()
                    try:
                        # å°è¯•è§£æJSONæ ¼å¼çš„å‚æ•°
                        if param_str.startswith('{') and param_str.endswith('}'):
                            arguments = json.loads(param_str)
                        else:
                            # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ç®€å•è§£æ
                            arguments = {"query": param_str}
                    except json.JSONDecodeError:
                        arguments = {"query": param_str}
                elif line.startswith('åŸå› :'):
                    reason = line.split(':', 1)[1].strip()
            
            if tool_name:
                return {
                    "tool_name": tool_name,
                    "arguments": arguments,
                    "reason": reason
                }
            
        except Exception as e:
            logger.error(f"è§£æå·¥å…·è°ƒç”¨å†³ç­–å¤±è´¥: {e}")
        
        return None
    
    def _update_analysis_data(self, analysis_results: Dict[str, Any], 
                             tool_name: str, result: Dict[str, Any]):
        """æ ¹æ®å·¥å…·è°ƒç”¨ç»“æœæ›´æ–°åˆ†ææ•°æ®"""
        if tool_name == "maps_geo":
            # åœ°ç†ç¼–ç ç»“æœ
            coords, city = self._extract_coordinates_and_city(result)
            if coords:
                if "work_location1" not in analysis_results["coordinates"]:
                    analysis_results["coordinates"]["work_location1"] = coords
                    analysis_results["coordinates"]["city1"] = city
                elif "work_location2" not in analysis_results["coordinates"]:
                    analysis_results["coordinates"]["work_location2"] = coords
                    analysis_results["coordinates"]["city2"] = city
                
        elif tool_name in ["maps_direction_transit_integrated", "maps_direction_walking"]:
            # è·¯çº¿ä¿¡æ¯
            if "routes" not in analysis_results["analysis_data"]:
                analysis_results["analysis_data"]["routes"] = []
            analysis_results["analysis_data"]["routes"].append(result)
            
        elif tool_name == "maps_around_search":
            # å‘¨è¾¹æœç´¢ç»“æœ
            if "poi_data" not in analysis_results["analysis_data"]:
                analysis_results["analysis_data"]["poi_data"] = []
            analysis_results["analysis_data"]["poi_data"].append(result)
            
        elif tool_name == "maps_text_search":
            # æ–‡æœ¬æœç´¢ç»“æœ
            if "search_results" not in analysis_results["analysis_data"]:
                analysis_results["analysis_data"]["search_results"] = []
            analysis_results["analysis_data"]["search_results"].append(result)
    
    def _extract_coordinates_and_city(self, geocode_result: Dict[str, Any]) -> tuple[Optional[str], Optional[str]]:
        """ä»åœ°ç†ç¼–ç ç»“æœä¸­æå–åæ ‡å’ŒåŸå¸‚ä¿¡æ¯"""
        try:
            if isinstance(geocode_result, dict):
                if "result" in geocode_result:
                    result_data = geocode_result["result"]
                    if "content" in result_data and isinstance(result_data["content"], list):
                        content = result_data["content"]
                        if len(content) > 0 and "text" in content[0]:
                            text_content = content[0]["text"]
                            parsed_data = json.loads(text_content)
                            if "results" in parsed_data and parsed_data["results"]:
                                first_result = parsed_data["results"][0]
                                location = first_result.get("location")
                                city = first_result.get("city", "").replace("å¸‚", "")
                                province = first_result.get("province", "").replace("å¸‚", "")
                                detected_city = city if city else province
                                return location, detected_city
            return None, None
        except Exception as e:
            logger.error(f"æå–åæ ‡å¤±è´¥: {e}")
            return None, None
    
    def _generate_current_status(self, analysis_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå½“å‰åˆ†æçŠ¶æ€çš„æè¿°"""
        status_parts = []
        
        # åŸºæœ¬ä¿¡æ¯
        status_parts.append(f"ç›®æ ‡: ä¸ºç”¨æˆ·æ‰¾åˆ°è¿æ¥'{analysis_results['work_address1']}'å’Œ'{analysis_results['work_address2']}'çš„æœ€ä½³ç§Ÿæˆ¿ä½ç½®")
        
        # åæ ‡ä¿¡æ¯
        coords = analysis_results["coordinates"]
        if coords:
            status_parts.append(f"å·²è·å–åæ ‡: {len(coords)}ä¸ªä½ç½®")
            for key, value in coords.items():
                if key.startswith("work_location"):
                    status_parts.append(f"  - {key}: {value}")
        else:
            status_parts.append("å°šæœªè·å–å·¥ä½œåœ°ç‚¹åæ ‡")
        
        # å·¥å…·è°ƒç”¨ç»Ÿè®¡
        tool_calls = analysis_results["tool_calls"]
        if tool_calls:
            status_parts.append(f"å·²æ‰§è¡Œå·¥å…·è°ƒç”¨: {len(tool_calls)}æ¬¡")
            tool_summary = {}
            for call in tool_calls:
                tool_name = call["tool_name"]
                tool_summary[tool_name] = tool_summary.get(tool_name, 0) + 1
            for tool_name, count in tool_summary.items():
                status_parts.append(f"  - {tool_name}: {count}æ¬¡")
        else:
            status_parts.append("å°šæœªæ‰§è¡Œä»»ä½•å·¥å…·è°ƒç”¨")
        
        # åˆ†ææ•°æ®ç»Ÿè®¡
        analysis_data = analysis_results["analysis_data"]
        if analysis_data:
            status_parts.append("å·²æ”¶é›†çš„æ•°æ®ç±»å‹:")
            for data_type, data in analysis_data.items():
                if isinstance(data, list):
                    status_parts.append(f"  - {data_type}: {len(data)}æ¡è®°å½•")
                else:
                    status_parts.append(f"  - {data_type}: å·²æ”¶é›†")
        
        return "\n".join(status_parts)
    
    def _format_tool_calls_history(self, tool_calls: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å·¥å…·è°ƒç”¨å†å²"""
        if not tool_calls:
            return "æ— "
        
        formatted = []
        for i, call in enumerate(tool_calls, 1):
            formatted.append(f"{i}. {call['tool_name']}")
            formatted.append(f"   å‚æ•°: {call['arguments']}")
            formatted.append(f"   åŸå› : {call.get('reason', 'æœªè¯´æ˜')}")
            if 'error' in call:
                formatted.append(f"   ç»“æœ: å¤±è´¥ - {call['error']}")
            else:
                formatted.append(f"   ç»“æœ: æˆåŠŸ")
        
        return "\n".join(formatted)
    
    async def _generate_final_analysis(self, analysis_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæœ€ç»ˆçš„ç§Ÿæˆ¿åˆ†ææŠ¥å‘Š"""
        
        # æ„å»ºè¯¦ç»†çš„æ•°æ®æ€»ç»“ç»™LLMï¼Œå‚è€ƒhouse.pyçš„promptæ ¼å¼
        coordinates = analysis_results.get("coordinates", {})
        work_address1 = analysis_results['work_address1']
        work_address2 = analysis_results['work_address2']
        budget_range = analysis_results['budget_range']
        preferences = analysis_results['preferences']
        
        # è·å–åæ ‡å’ŒåŸå¸‚ä¿¡æ¯
        location1_coords = coordinates.get('work_location1', 'unknown')
        location2_coords = coordinates.get('work_location2', 'unknown')
        target_city = coordinates.get('city1') or coordinates.get('city2')
        
        # æ„å»ºä¸­ç‚¹åæ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        midpoint = "calculated by intelligent analyzer"
        if location1_coords != 'unknown' and location2_coords != 'unknown':
            try:
                lon1, lat1 = map(float, location1_coords.split(','))
                lon2, lat2 = map(float, location2_coords.split(','))
                mid_lon = (lon1 + lon2) / 2
                mid_lat = (lat1 + lat2) / 2
                midpoint = f"{mid_lon},{mid_lat}"
            except:
                pass
        
        # æ£€æŸ¥æ˜¯å¦æœ‰äº¤é€šä¿¡æ¯
        transit_available = False
        transit_error = "æš‚æ— è·¯çº¿ä¿¡æ¯"
        transit_data = ""
        
        # ä»å·¥å…·è°ƒç”¨ç»“æœä¸­æŸ¥æ‰¾äº¤é€šä¿¡æ¯
        for call in analysis_results.get("tool_calls", []):
            if "direction" in call.get("tool_name", ""):
                if 'result' in call and not call.get('error'):
                    result = call['result']
                    result_content = result.get("result", {})
                    if not result_content.get("isError", True):
                        transit_available = True
                        transit_data = json.dumps(result, ensure_ascii=False, indent=2)
                        break
                    else:
                        content = result_content.get('content', [])
                        if content and len(content) > 0:
                            transit_error = content[0].get('text', 'äº¤é€šè·¯çº¿æŸ¥è¯¢å¤±è´¥')
        
        # å‡†å¤‡è¯¦ç»†çš„æ•°æ®å±•ç¤º
        analysis_data = analysis_results.get("analysis_data", {})
        residential_areas_data = ""
        life_facilities_data = ""
        transport_hubs_data = ""
        popular_areas_data = ""
        commute_analysis_data = ""
        
        # ä»å·¥å…·è°ƒç”¨ç»“æœä¸­æå–å„ç±»æ•°æ®
        for call in analysis_results.get("tool_calls", []):
            tool_name = call.get("tool_name", "")
            if 'result' in call and not call.get('error'):
                if "around_search" in tool_name:
                    args = call.get("arguments", {})
                    keywords = args.get("keywords", "")
                    if "ä½å®…" in keywords or "å…¬å¯“" in keywords or "ç§Ÿæˆ¿" in keywords:
                        residential_areas_data = json.dumps(call['result'], ensure_ascii=False, indent=2)
                    elif "è¶…å¸‚" in keywords or "èœå¸‚åœº" in keywords or "åŒ»é™¢" in keywords or "é“¶è¡Œ" in keywords:
                        life_facilities_data = json.dumps(call['result'], ensure_ascii=False, indent=2)
                    elif "åœ°é“ç«™" in keywords or "å…¬äº¤ç«™" in keywords:
                        transport_hubs_data = json.dumps(call['result'], ensure_ascii=False, indent=2)
                elif "text_search" in tool_name:
                    popular_areas_data = json.dumps(call['result'], ensure_ascii=False, indent=2)
        
        # æ„å»ºé€šå‹¤åˆ†ææ•°æ®
        commute_calls = [call for call in analysis_results.get("tool_calls", []) 
                        if "direction" in call.get("tool_name", "") and 'result' in call and not call.get('error')]
        if commute_calls:
            commute_analysis_data = json.dumps([call['result'] for call in commute_calls], ensure_ascii=False, indent=2)
        
        # å‡†å¤‡ç»™ Gemini çš„ä¼˜åŒ–æç¤ºï¼ˆç¼©çŸ­æ•°æ®éƒ¨åˆ†ï¼Œä¿æŒè¯¦ç»†è¾“å‡ºï¼‰
        city_info = f"åœ¨{target_city}" if target_city else "åœ¨æ£€æµ‹åˆ°çš„åŸå¸‚"
        budget_info = f"é¢„ç®—èŒƒå›´ï¼š{budget_range}" if budget_range != "ä¸é™" else "é¢„ç®—ï¼šæ— ç‰¹æ®Šé™åˆ¶"
        preferences_info = f"ç‰¹æ®Šåå¥½ï¼š{preferences}" if preferences else "æ— ç‰¹æ®Šåå¥½"
        
        # ç²¾ç®€æ•°æ®å±•ç¤ºï¼Œé¿å…promptè¿‡é•¿å¯¼è‡´è¶…æ—¶
        data_summary = ""
        if transit_available:
            data_summary += "âœ… å·²è·å–äº¤é€šè·¯çº¿æ•°æ®\n"
        if residential_areas_data:
            data_summary += "âœ… å·²è·å–ä½å®…åŒºåŸŸæ•°æ®\n"
        if life_facilities_data:
            data_summary += "âœ… å·²è·å–ç”Ÿæ´»è®¾æ–½æ•°æ®\n"
        if transport_hubs_data:
            data_summary += "âœ… å·²è·å–äº¤é€šæ¢çº½æ•°æ®\n"
        if popular_areas_data:
            data_summary += "âœ… å·²è·å–çƒ­é—¨åŒºåŸŸæ•°æ®\n"
        if commute_analysis_data:
            data_summary += "âœ… å·²è·å–é€šå‹¤åˆ†ææ•°æ®\n"
        
        final_prompt = f"""
        è¯·ä¸ºç§Ÿæˆ¿éœ€æ±‚ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼š

        åŸºæœ¬ä¿¡æ¯ï¼š
        - å·¥ä½œåœ°ç‚¹A: {work_address1}
        - å·¥ä½œåœ°ç‚¹B: {work_address2}
        - åŸå¸‚: {target_city}
        - {budget_info}
        - {preferences_info}

        æ•°æ®æ”¶é›†çŠ¶å†µï¼š
        {data_summary}

        è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹ç»“æ„çš„è¯¦ç»†æŠ¥å‘Šï¼š

        ## ğŸ  æ¨èç§Ÿæˆ¿åŒºåŸŸ

        ### ğŸŒŸ æ¨èåŒºåŸŸ1: [å…·ä½“åŒºåŸŸåç§°]
        **æ¨èç†ç”±ï¼š** [è¯¦ç»†åˆ†æé€šå‹¤ä¾¿åˆ©æ€§]
        **åŒºåŸŸç‰¹ç‚¹ï¼š** [ç¯å¢ƒã€æˆ¿æºã€ç”Ÿæ´»æ°›å›´]
        **é¢„ä¼°ç§Ÿé‡‘ï¼š** [å…·ä½“ä»·æ ¼èŒƒå›´]
        **ç”Ÿæ´»ä¾¿åˆ©åº¦ï¼š** â­â­â­â­â­

        #### ğŸš‡ åˆ°å·¥ä½œåœ°ç‚¹Açš„é€šå‹¤ï¼š
        **æœ€ä½³è·¯çº¿ï¼š**
        1. æ­¥è¡Œåˆ°åœ°é“ç«™ï¼š[ç«™å]ï¼Œçº¦[X]åˆ†é’Ÿ
        2. åœ°é“è·¯çº¿ï¼š[çº¿è·¯]ä»[èµ·ç«™]åˆ°[ç»ˆç«™]ï¼Œçº¦[X]åˆ†é’Ÿ
        3. æ­¥è¡Œåˆ°å·¥ä½œåœ°ç‚¹ï¼šçº¦[X]åˆ†é’Ÿ
        **æ€»æ—¶é—´ï¼šçº¦[X]åˆ†é’Ÿï¼Œè´¹ç”¨ï¼š[X]å…ƒ/å¤©**

        #### ğŸš‡ åˆ°å·¥ä½œåœ°ç‚¹Bçš„é€šå‹¤ï¼š
        **æœ€ä½³è·¯çº¿ï¼š**
        1. æ­¥è¡Œåˆ°åœ°é“ç«™ï¼š[ç«™å]ï¼Œçº¦[X]åˆ†é’Ÿ
        2. åœ°é“è·¯çº¿ï¼š[çº¿è·¯]ä»[èµ·ç«™]åˆ°[ç»ˆç«™]ï¼Œçº¦[X]åˆ†é’Ÿ
        3. æ­¥è¡Œåˆ°å·¥ä½œåœ°ç‚¹ï¼šçº¦[X]åˆ†é’Ÿ
        **æ€»æ—¶é—´ï¼šçº¦[X]åˆ†é’Ÿï¼Œè´¹ç”¨ï¼š[X]å…ƒ/å¤©**

        #### ğŸ˜ï¸ å‘¨è¾¹è®¾æ–½ï¼š
        - è´­ç‰©ï¼š[å…·ä½“å•†åœºã€è¶…å¸‚]
        - é¤é¥®ï¼š[é¤å…ç±»å‹ã€å¤–å–ä¾¿åˆ©åº¦]
        - åŒ»ç–—ï¼š[åŒ»é™¢ã€è¯Šæ‰€]
        - äº¤é€šï¼š[åœ°é“ç«™ã€å…¬äº¤çº¿è·¯]

        ### ğŸŒŸ æ¨èåŒºåŸŸ2: [ç¬¬äºŒä¸ªåŒºåŸŸ]
        [å®Œæ•´çš„ç±»ä¼¼ç»“æ„åˆ†æ]

        ### ğŸŒŸ æ¨èåŒºåŸŸ3: [ç¬¬ä¸‰ä¸ªåŒºåŸŸ]
        [å®Œæ•´çš„ç±»ä¼¼ç»“æ„åˆ†æ]

        ## ğŸ“Š åŒºåŸŸå¯¹æ¯”åˆ†æ

        | åŒºåŸŸ | é€šå‹¤ä¾¿åˆ©åº¦ | ç”Ÿæ´»ä¾¿åˆ©åº¦ | é¢„ä¼°ç§Ÿé‡‘ | ç¯å¢ƒè´¨é‡ | ç»¼åˆæ¨èåº¦ |
        |------|-----------|-----------|----------|----------|-----------|
        | åŒºåŸŸ1 | â­â­â­â­â­ | â­â­â­â­ | ä¸­ç­‰ | â­â­â­â­ | â­â­â­â­â­ |
        | åŒºåŸŸ2 | â­â­â­â­ | â­â­â­â­â­ | è¾ƒé«˜ | â­â­â­â­â­ | â­â­â­â­ |
        | åŒºåŸŸ3 | â­â­â­ | â­â­â­ | è¾ƒä½ | â­â­â­ | â­â­â­ |

        ## ğŸ’¡ å®ç”¨å»ºè®®

        ### é€‰æˆ¿è¦ç‚¹ï¼š
        - äº¤é€šä¼˜å…ˆï¼š[å…·ä½“å»ºè®®]
        - ç”Ÿæ´»é…å¥—ï¼š[å¿…å¤‡è®¾æ–½]
        - æ€§ä»·æ¯”ï¼š[ç§Ÿé‡‘å»ºè®®]

        ### æˆæœ¬åˆ†æï¼š
        - æœˆäº¤é€šè´¹ï¼š[è¯¦ç»†è®¡ç®—]
        - ç”Ÿæ´»æˆæœ¬ï¼š[å‘¨è¾¹æ¶ˆè´¹]
        - æ—¶é—´æˆæœ¬ï¼š[é€šå‹¤æ—¶é—´ä»·å€¼]

        ### çœ‹æˆ¿æ¸…å•ï¼š
        - [ ] å®åœ°ä½“éªŒé€šå‹¤è·¯çº¿
        - [ ] æ£€æŸ¥ç½‘ç»œä¿¡å·
        - [ ] äº†è§£æ°´ç”µè´¹ç”¨
        - [ ] æŸ¥çœ‹å®‰å…¨çŠ¶å†µ

        è¯·åŸºäº{target_city}å®é™…æƒ…å†µï¼Œæä¾›å…·ä½“è¯¦ç»†çš„ç§Ÿæˆ¿å»ºè®®ï¼Œç¡®ä¿ä¸‰ä¸ªåŒºåŸŸéƒ½æœ‰å®Œæ•´çš„é€šå‹¤åˆ†æã€‚
        """
        
        try:
            logger.info("å¼€å§‹è°ƒç”¨Geminiç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Š...")
            
            # è®¾ç½®ç”Ÿæˆé…ç½®ï¼Œå»æ‰tokené™åˆ¶ï¼Œé™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§
            generation_config = genai.types.GenerationConfig(
                temperature=0.2,  # é™ä½æ¸©åº¦ä»¥æé«˜å‡†ç¡®æ€§å’Œä¸€è‡´æ€§
                candidate_count=1
            )
            
            response = self.model.generate_content(
                final_prompt,
                generation_config=generation_config
            )
            
            logger.info("Geminiåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return response.text
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            logger.info(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
            
            # å°è¯•ä½¿ç”¨æ›´ç®€åŒ–çš„prompté‡æ–°ç”Ÿæˆ
            try:
                logger.info("å°è¯•ä½¿ç”¨ç®€åŒ–prompté‡æ–°ç”Ÿæˆ...")
                simplified_analysis = await self._generate_simplified_analysis(analysis_results)
                return simplified_analysis
            except Exception as e2:
                logger.error(f"ç®€åŒ–åˆ†æä¹Ÿå¤±è´¥: {e2}")
                # æœ€åçš„fallback
                fallback_analysis = self._generate_fallback_analysis(analysis_results)
                logger.info("ä½¿ç”¨æœ€åŸºç¡€çš„fallbackåˆ†ææŠ¥å‘Š")
                return fallback_analysis
    
    def _build_data_summary_for_llm(self, analysis_results: Dict[str, Any]) -> str:
        """ä¸ºLLMæ„å»ºæ•°æ®æ€»ç»“"""
        summary_parts = []
        
        # åæ ‡ä¿¡æ¯
        coords = analysis_results["coordinates"]
        if coords:
            summary_parts.append("**åæ ‡ä¿¡æ¯:**")
            for key, value in coords.items():
                summary_parts.append(f"- {key}: {value}")
        
        # å·¥å…·è°ƒç”¨ç»“æœ
        tool_calls = analysis_results["tool_calls"]
        if tool_calls:
            summary_parts.append("\n**å·¥å…·è°ƒç”¨ç»“æœ:**")
            for call in tool_calls:
                summary_parts.append(f"- {call['tool_name']}: {call.get('reason', 'æ•°æ®æ”¶é›†')}")
                if 'result' in call and not call.get('error'):
                    # ç®€åŒ–ç»“æœæ˜¾ç¤º
                    result_summary = self._summarize_tool_result(call['tool_name'], call['result'])
                    summary_parts.append(f"  ç»“æœ: {result_summary}")
        
        # åˆ†ææ•°æ®
        analysis_data = analysis_results["analysis_data"]
        if analysis_data:
            summary_parts.append("\n**æ”¶é›†çš„åˆ†ææ•°æ®:**")
            for data_type, data in analysis_data.items():
                summary_parts.append(f"- {data_type}: {self._summarize_data_type(data_type, data)}")
        
        return "\n".join(summary_parts)
    
    def _summarize_tool_result(self, tool_name: str, result: Dict[str, Any]) -> str:
        """æ€»ç»“å·¥å…·è°ƒç”¨ç»“æœ"""
        try:
            if tool_name == "maps_geo":
                coords, city = self._extract_coordinates_and_city(result)
                return f"åæ ‡: {coords}, åŸå¸‚: {city}"
            elif "direction" in tool_name:
                return "è·¯çº¿ä¿¡æ¯å·²è·å–"
            elif "search" in tool_name:
                return "æœç´¢ç»“æœå·²è·å–"
            else:
                return "æ•°æ®å·²æ”¶é›†"
        except:
            return "å·²å¤„ç†"
    
    def _summarize_data_type(self, data_type: str, data: Any) -> str:
        """æ€»ç»“æ•°æ®ç±»å‹"""
        if isinstance(data, list):
            return f"{len(data)}æ¡è®°å½•"
        else:
            return "å·²æ”¶é›†"
    
    async def _generate_simplified_analysis(self, analysis_results: Dict[str, Any]) -> str:
        """ä½¿ç”¨ç®€åŒ–promptç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        coordinates = analysis_results.get("coordinates", {})
        work_address1 = analysis_results['work_address1']
        work_address2 = analysis_results['work_address2']
        budget_range = analysis_results['budget_range']
        preferences = analysis_results['preferences']
        
        location1_coords = coordinates.get('work_location1', 'unknown')
        location2_coords = coordinates.get('work_location2', 'unknown')
        target_city = coordinates.get('city1') or coordinates.get('city2', 'ä¸Šæµ·')
        
        # æå–å…³é”®æ•°æ®
        tool_calls = analysis_results.get("tool_calls", [])
        successful_calls = [call for call in tool_calls if 'error' not in call]
        
        # æ„å»ºç®€åŒ–ä½†è¯¦ç»†çš„prompt
        simplified_prompt = f"""
        è¯·ä¸ºç§Ÿæˆ¿éœ€æ±‚ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼š

        åŸºæœ¬ä¿¡æ¯ï¼š
        - å·¥ä½œåœ°ç‚¹A: {work_address1}
        - å·¥ä½œåœ°ç‚¹B: {work_address2}
        - åŸå¸‚: {target_city}
        - é¢„ç®—: {budget_range}
        - åå¥½: {preferences}
        - å·²æ”¶é›†æ•°æ®: {len(successful_calls)}é¡¹

        è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„è¯¦ç»†æŠ¥å‘Šï¼š

        ## ğŸ  æ¨èç§Ÿæˆ¿åŒºåŸŸ

        ### ğŸŒŸ æ¨èåŒºåŸŸ1: [å…·ä½“åŒºåŸŸåç§°]
        **æ¨èç†ç”±ï¼š** [è¯¦ç»†ç†ç”±]
        **åŒºåŸŸç‰¹ç‚¹ï¼š** [ç¯å¢ƒæè¿°]
        **é¢„ä¼°ç§Ÿé‡‘ï¼š** [å…·ä½“èŒƒå›´]
        **ç”Ÿæ´»ä¾¿åˆ©åº¦ï¼š** â­â­â­â­â­

        #### ğŸš‡ é€šå‹¤åˆ†æ:
        - **åˆ°å·¥ä½œåœ°ç‚¹A**: åœ°é“[X]çº¿ï¼Œçº¦[X]åˆ†é’Ÿï¼Œè´¹ç”¨[X]å…ƒ/å¤©
        - **åˆ°å·¥ä½œåœ°ç‚¹B**: åœ°é“[Y]çº¿ï¼Œçº¦[Y]åˆ†é’Ÿï¼Œè´¹ç”¨[Y]å…ƒ/å¤©

        #### ğŸ˜ï¸ å‘¨è¾¹è®¾æ–½:
        - è´­ç‰©ã€é¤é¥®ã€åŒ»ç–—ã€äº¤é€šç­‰è¯¦ç»†ä¿¡æ¯

        ### ğŸŒŸ æ¨èåŒºåŸŸ2: [ç¬¬äºŒä¸ªåŒºåŸŸ]
        [ç±»ä¼¼è¯¦ç»†ç»“æ„]

        ### ğŸŒŸ æ¨èåŒºåŸŸ3: [ç¬¬ä¸‰ä¸ªåŒºåŸŸ]
        [ç±»ä¼¼è¯¦ç»†ç»“æ„]

        ## ğŸ“Š åŒºåŸŸå¯¹æ¯”åˆ†æ
        [è¡¨æ ¼å¯¹æ¯”]

        ## ğŸ’¡ å®ç”¨å»ºè®®
        [è¯¦ç»†çš„é€‰æˆ¿å»ºè®®]

        åŸºäº{target_city}çš„å®é™…æƒ…å†µï¼Œæä¾›å…·ä½“å®ç”¨çš„ç§Ÿæˆ¿å»ºè®®ã€‚
        """
        
        try:
            generation_config = genai.types.GenerationConfig(
                temperature=0.1,
                candidate_count=1
            )
            
            response = self.model.generate_content(
                simplified_prompt,
                generation_config=generation_config
            )
            
            return response.text
            
        except Exception as e:
            logger.error(f"ç®€åŒ–åˆ†æå¤±è´¥: {e}")
            raise e

    def _generate_fallback_analysis(self, analysis_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤‡ç”¨çš„ç®€åŒ–åˆ†ææŠ¥å‘Š"""
        coordinates = analysis_results.get("coordinates", {})
        work_address1 = analysis_results['work_address1']
        work_address2 = analysis_results['work_address2']
        budget_range = analysis_results['budget_range']
        preferences = analysis_results['preferences']
        
        location1_coords = coordinates.get('work_location1', 'unknown')
        location2_coords = coordinates.get('work_location2', 'unknown')
        target_city = coordinates.get('city1') or coordinates.get('city2', 'æœªçŸ¥åŸå¸‚')
        
        # ç»Ÿè®¡å·¥å…·è°ƒç”¨ç»“æœ
        tool_calls = analysis_results.get("tool_calls", [])
        successful_calls = [call for call in tool_calls if 'error' not in call]
        
        fallback_report = f"""
# ğŸ  æ™ºèƒ½ç§Ÿæˆ¿ä½ç½®åˆ†ææŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **å·¥ä½œåœ°ç‚¹A**: {work_address1}
- **å·¥ä½œåœ°ç‚¹B**: {work_address2}
- **æ£€æµ‹åŸå¸‚**: {target_city}
- **é¢„ç®—èŒƒå›´**: {budget_range}
- **ç‰¹æ®Šåå¥½**: {preferences or 'æ— '}

## æ•°æ®æ”¶é›†çŠ¶å†µ
- **æˆåŠŸæ‰§è¡Œçš„å·¥å…·è°ƒç”¨**: {len(successful_calls)}æ¬¡
- **è·å–åˆ°çš„åæ ‡ä¿¡æ¯**: {'æ˜¯' if location1_coords != 'unknown' and location2_coords != 'unknown' else 'å¦'}

## ğŸŒŸ æ¨èåŒºåŸŸ

### æ¨èåŒºåŸŸ1: {target_city}å¸‚ä¸­å¿ƒåŒºåŸŸ
**æ¨èç†ç”±**: ä½äºåŸå¸‚ä¸­å¿ƒï¼Œäº¤é€šç½‘ç»œå‘è¾¾ï¼Œåˆ°ä¸¤ä¸ªå·¥ä½œåœ°ç‚¹éƒ½ç›¸å¯¹ä¾¿åˆ©ã€‚
**é¢„ä¼°ç§Ÿé‡‘**: æ ¹æ®{target_city}å¸‚åœºä»·æ ¼ï¼Œé¢„è®¡æœˆç§Ÿé‡‘åœ¨{budget_range}èŒƒå›´å†…ã€‚
**ç”Ÿæ´»ä¾¿åˆ©åº¦**: â­â­â­â­

### æ¨èåŒºåŸŸ2: ä¸¤ä¸ªå·¥ä½œåœ°ç‚¹çš„ä¸­é—´åŒºåŸŸ
**æ¨èç†ç”±**: ä½äºä¸¤ä¸ªå·¥ä½œåœ°ç‚¹çš„å‡ ä½•ä¸­å¿ƒé™„è¿‘ï¼Œé€šå‹¤è·ç¦»ç›¸å¯¹å‡è¡¡ã€‚
**é¢„ä¼°ç§Ÿé‡‘**: ä¸­ç­‰ä»·ä½åŒºåŸŸã€‚
**ç”Ÿæ´»ä¾¿åˆ©åº¦**: â­â­â­â­

### æ¨èåŒºåŸŸ3: äº¤é€šæ¢çº½é™„è¿‘
**æ¨èç†ç”±**: é è¿‘åœ°é“ç«™æˆ–é‡è¦äº¤é€šæ¢çº½ï¼Œæ¢ä¹˜ä¾¿åˆ©ã€‚
**é¢„ä¼°ç§Ÿé‡‘**: å› äº¤é€šä¾¿åˆ©ï¼Œç§Ÿé‡‘å¯èƒ½ç•¥é«˜ã€‚
**ç”Ÿæ´»ä¾¿åˆ©åº¦**: â­â­â­â­â­

## ğŸ’¡ é€‰æˆ¿å»ºè®®

1. **äº¤é€šä¼˜å…ˆ**: é€‰æ‹©è·ç¦»åœ°é“ç«™æ­¥è¡Œ10åˆ†é’Ÿä»¥å†…çš„æˆ¿æº
2. **ç”Ÿæ´»é…å¥—**: ç¡®ä¿å‘¨è¾¹æœ‰è¶…å¸‚ã€åŒ»é™¢ç­‰åŸºæœ¬ç”Ÿæ´»è®¾æ–½
3. **å®åœ°è€ƒå¯Ÿ**: å»ºè®®å®åœ°ä½“éªŒé€šå‹¤è·¯çº¿ï¼Œç¡®è®¤å®é™…é€šå‹¤æ—¶é—´
4. **å®‰å…¨è€ƒè™‘**: é€‰æ‹©æ²»å®‰è‰¯å¥½çš„å°åŒºå’ŒåŒºåŸŸ

## âš ï¸ æ³¨æ„äº‹é¡¹
æœ¬æŠ¥å‘ŠåŸºäºæœ‰é™çš„æ•°æ®ç”Ÿæˆã€‚å»ºè®®ï¼š
- è¿›ä¸€æ­¥å®åœ°è°ƒç ”å…·ä½“åŒºåŸŸ
- ä½¿ç”¨åœ°å›¾è½¯ä»¶è§„åˆ’å…·ä½“é€šå‹¤è·¯çº¿
- å’¨è¯¢å½“åœ°æˆ¿äº§ä¸­ä»‹è·å–æœ€æ–°æˆ¿æºä¿¡æ¯

*æ³¨ï¼šç”±äºæŠ€æœ¯åŸå› ï¼Œæœ¬æ¬¡æœªèƒ½è·å–å®Œæ•´çš„åœ°å›¾æ•°æ®ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šçš„æˆ¿äº§æœç´¢å¹³å°è¿›è¡Œè¿›ä¸€æ­¥åˆ†æã€‚*
        """
        
        return fallback_report.strip()

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    analyzer = IntelligentRentalAnalyzer()
    
    # æµ‹è¯•åˆ†æ
    result = await analyzer.analyze_rental_locations(
        work_address1="åŒ—äº¬å¸‚æµ·æ·€åŒºä¸­å…³æ‘å¤§è¡—1å·",
        work_address2="åŒ—äº¬å¸‚æœé˜³åŒºå›½è´¸CBD",
        budget_range="5000-8000å…ƒ",
        preferences="é è¿‘åœ°é“ï¼Œç¯å¢ƒå®‰é™"
    )
    
    print("æ™ºèƒ½åˆ†æç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    asyncio.run(example_usage())
