import os
import json
import asyncio
import google.generativeai as genai
from typing import Dict, List, Any, Optional
import logging
from dotenv import load_dotenv
import aiohttp

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½® Google Gemini API
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("No GOOGLE_API_KEY found in environment variables.")
genai.configure(api_key=GEMINI_API_KEY)

# é«˜å¾·åœ°å›¾ MCP æœåŠ¡å™¨é…ç½®
AMAP_MCP_KEY = os.getenv("AMAP_MCP_KEY")
AMAP_MCP_URL = f"https://mcp.amap.com/mcp?key={AMAP_MCP_KEY}"

class MCPToolManager:
    """MCPå·¥å…·ç®¡ç†å™¨ï¼Œè´Ÿè´£ä¸MCPæœåŠ¡å™¨é€šä¿¡"""
    
    def __init__(self, url: str):
        self.url = url
        self.session = None
        self.request_id = 0
        self.available_tools = {}
    
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        await self.initialize()
        await self.load_available_tools()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    def _next_id(self):
        self.request_id += 1
        return self.request_id
    
    async def initialize(self):
        """åˆå§‹åŒ– MCP è¿æ¥"""
        payload = {
            "jsonrpc": "2.0",
            "id": self._next_id(),
            "method": "initialize",
            "params": {
                "protocolVersion": "2024-11-05",
                "capabilities": {"tools": {}},
                "clientInfo": {
                    "name": "intelligent-rental-analyzer",
                    "version": "1.0.0"
                }
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }
        
        async with self.session.post(self.url, json=payload, headers=headers) as response:
            if response.status != 200:
                raise Exception("MCP initialization failed")
            result = await response.json()
            return result
    
    async def load_available_tools(self):
        """åŠ è½½å¯ç”¨å·¥å…·åˆ—è¡¨å¹¶æ„å»ºå·¥å…·æè¿°"""
        payload = {
            "jsonrpc": "2.0",
            "id": self._next_id(),
            "method": "tools/list",
            "params": {}
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }
        
        async with self.session.post(self.url, json=payload, headers=headers) as response:
            if response.status == 200:
                result = await response.json()
                if "result" in result and "tools" in result["result"]:
                    for tool in result["result"]["tools"]:
                        self.available_tools[tool["name"]] = tool
                        logger.info(f"Loaded tool: {tool['name']}")
    
    async def call_tool(self, tool_name: str, arguments: dict):
        """è°ƒç”¨æŒ‡å®šçš„MCPå·¥å…·"""
        payload = {
            "jsonrpc": "2.0",
            "id": self._next_id(),
            "method": "tools/call",
            "params": {
                "name": tool_name,
                "arguments": arguments
            }
        }
        
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }
        
        logger.info(f"Calling tool {tool_name} with arguments: {arguments}")
        async with self.session.post(self.url, json=payload, headers=headers) as response:
            if response.status != 200:
                text = await response.text()
                logger.error(f"Failed to call tool {tool_name}: {text}")
                return {"error": f"Failed to call tool {tool_name}"}
            result = await response.json()
            logger.info(f"Tool {tool_name} result received")
            return result
    
    def get_tools_description(self) -> str:
        """ç”Ÿæˆå·¥å…·æè¿°ï¼Œä¾›LLMç†è§£å¯ç”¨å·¥å…·"""
        descriptions = []
        for tool_name, tool_info in self.available_tools.items():
            desc = f"**{tool_name}**: {tool_info.get('description', 'æ— æè¿°')}"
            if 'inputSchema' in tool_info:
                schema = tool_info['inputSchema']
                if 'properties' in schema:
                    params = []
                    for param_name, param_info in schema['properties'].items():
                        param_desc = f"{param_name} ({param_info.get('type', 'unknown')})"
                        if param_info.get('description'):
                            param_desc += f": {param_info['description']}"
                        params.append(param_desc)
                    desc += f"\n  å‚æ•°: {', '.join(params)}"
            descriptions.append(desc)
        return "\n\n".join(descriptions)

class IntelligentRentalAnalyzer:
    """æ™ºèƒ½ç§Ÿæˆ¿ä½ç½®åˆ†æå™¨ï¼Œä½¿ç”¨LLMæ¨ç†èƒ½åŠ›æ™ºèƒ½è°ƒç”¨MCPå·¥å…·"""
    
    def __init__(self):
        self.model = genai.GenerativeModel('gemini-2.5-pro')
        self.conversation_history = []
        self.analysis_data = {}
    
    async def analyze_rental_locations(self, work_address1: str, work_address2: str, 
                                     budget_range: str = "ä¸é™", preferences: str = "") -> Dict[str, Any]:
        """ä½¿ç”¨LLMæ¨ç†èƒ½åŠ›è¿›è¡Œæ™ºèƒ½ç§Ÿæˆ¿åˆ†æ"""
        
        async with MCPToolManager(AMAP_MCP_URL) as tool_manager:
            # ç¬¬ä¸€æ­¥ï¼šè®©LLMç†è§£ä»»åŠ¡å¹¶åˆ¶å®šåˆ†æè®¡åˆ’
            initial_prompt = f"""
            æˆ‘æ˜¯ä¸€ä¸ªæ™ºèƒ½ç§Ÿæˆ¿ä½ç½®åˆ†æåŠ©æ‰‹ã€‚ç°åœ¨éœ€è¦ä¸ºç”¨æˆ·æ‰¾åˆ°æœ€ä½³ç§Ÿæˆ¿ä½ç½®ã€‚

            **ç”¨æˆ·éœ€æ±‚ï¼š**
            - å·¥ä½œåœ°ç‚¹A: {work_address1}
            - å·¥ä½œåœ°ç‚¹B: {work_address2}  
            - é¢„ç®—èŒƒå›´: {budget_range}
            - ç‰¹æ®Šåå¥½: {preferences if preferences else "æ— "}

            **å¯ç”¨çš„åœ°å›¾APIå·¥å…·ï¼š**
            {tool_manager.get_tools_description()}

            è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œåˆ¶å®šä¸€ä¸ªè¯¦ç»†çš„åˆ†æè®¡åˆ’ã€‚ä½ éœ€è¦ï¼š
            1. åˆ†æéœ€è¦æ”¶é›†å“ªäº›ä¿¡æ¯
            2. ç¡®å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·åŠå…¶è°ƒç”¨é¡ºåº
            3. è¯´æ˜æ¯ä¸ªå·¥å…·è°ƒç”¨çš„ç›®çš„å’ŒæœŸæœ›ç»“æœ

            è¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
            ## åˆ†æè®¡åˆ’
            
            ### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ä¿¡æ¯æ”¶é›†
            - å·¥å…·åç§°ï¼šxxx
            - è°ƒç”¨ç›®çš„ï¼šxxx
            - é¢„æœŸç»“æœï¼šxxx
            
            ### ç¬¬äºŒé˜¶æ®µï¼šxxx
            ...
            
            è¯·å¼€å§‹åˆ¶å®šåˆ†æè®¡åˆ’ã€‚
            """
            
            # è·å–LLMçš„åˆ†æè®¡åˆ’
            plan_response = self.model.generate_content(initial_prompt)
            analysis_plan = plan_response.text
            self.conversation_history.append(("plan", analysis_plan))
            logger.info(f"LLMåˆ¶å®šçš„åˆ†æè®¡åˆ’:\n{analysis_plan}")
            
            # ç¬¬äºŒæ­¥ï¼šæ ¹æ®è®¡åˆ’é€æ­¥æ‰§è¡Œåˆ†æ
            return await self._execute_analysis_with_llm_guidance(
                tool_manager, work_address1, work_address2, budget_range, preferences
            )
    
    async def _execute_analysis_with_llm_guidance(self, tool_manager: MCPToolManager, 
                                                  work_address1: str, work_address2: str,
                                                  budget_range: str, preferences: str) -> Dict[str, Any]:
        """åœ¨LLMæŒ‡å¯¼ä¸‹æ‰§è¡Œåˆ†æ"""
        
        analysis_results = {
            "work_address1": work_address1,
            "work_address2": work_address2,
            "budget_range": budget_range,
            "preferences": preferences,
            "tool_calls": [],
            "coordinates": {},
            "analysis_data": {}
        }
        
        max_iterations = 10  # é˜²æ­¢æ— é™å¾ªç¯
        iteration = 0
        
        while iteration < max_iterations:
            iteration += 1
            
            # è¯¢é—®LLMä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
            current_status = self._generate_current_status(analysis_results)
            
            next_step_prompt = f"""
            å½“å‰åˆ†æçŠ¶æ€ï¼š
            {current_status}
            
            **å·²æ‰§è¡Œçš„å·¥å…·è°ƒç”¨ï¼š**
            {self._format_tool_calls_history(analysis_results["tool_calls"])}
            
            **å¯ç”¨å·¥å…·ï¼š**
            {tool_manager.get_tools_description()}
            
            æ ¹æ®å½“å‰çŠ¶æ€ï¼Œè¯·å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š
            1. å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·ï¼Œè¯·ç”¨ä»¥ä¸‹æ ¼å¼å›ç­”ï¼š
               ```
               CALL_TOOL
               å·¥å…·åç§°: xxx
               å‚æ•°: {{"param1": "value1", "param2": "value2"}}
               åŸå› : xxx
               ```
            
            2. å¦‚æœä¿¡æ¯æ”¶é›†å®Œæ¯•ï¼Œå¯ä»¥è¿›è¡Œæœ€ç»ˆåˆ†æï¼Œè¯·å›ç­”ï¼š
               ```
               GENERATE_ANALYSIS
               åŸå› : xxx
               ```
            
            3. å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œè¯·å›ç­”ï¼š
               ```
               NEED_MORE_INFO
               éœ€è¦çš„ä¿¡æ¯: xxx
               å»ºè®®çš„å·¥å…·: xxx
               ```
            
            è¯·åˆ†æå½“å‰æƒ…å†µå¹¶ç»™å‡ºå†³ç­–ã€‚
            """
            
            llm_decision = self.model.generate_content(next_step_prompt)
            decision_text = llm_decision.text.strip()
            
            logger.info(f"LLMå†³ç­– (ç¬¬{iteration}è½®): {decision_text}")
            
            # è§£æLLMçš„å†³ç­–
            if "CALL_TOOL" in decision_text:
                # æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
                tool_call_info = self._parse_tool_call_decision(decision_text)
                if tool_call_info:
                    tool_name = tool_call_info["tool_name"]
                    arguments = tool_call_info["arguments"]
                    reason = tool_call_info["reason"]
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    try:
                        result = await tool_manager.call_tool(tool_name, arguments)
                        analysis_results["tool_calls"].append({
                            "tool_name": tool_name,
                            "arguments": arguments,
                            "result": result,
                            "reason": reason,
                            "iteration": iteration
                        })
                        
                        # æ›´æ–°åˆ†ææ•°æ®
                        self._update_analysis_data(analysis_results, tool_name, result)
                        
                        logger.info(f"æˆåŠŸæ‰§è¡Œå·¥å…·è°ƒç”¨: {tool_name}")
                        
                    except Exception as e:
                        logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {tool_name}, é”™è¯¯: {e}")
                        analysis_results["tool_calls"].append({
                            "tool_name": tool_name,
                            "arguments": arguments,
                            "error": str(e),
                            "reason": reason,
                            "iteration": iteration
                        })
                
            elif "GENERATE_ANALYSIS" in decision_text:
                # ç”Ÿæˆæœ€ç»ˆåˆ†æ
                logger.info("LLMå†³å®šç”Ÿæˆæœ€ç»ˆåˆ†æ")
                final_analysis = await self._generate_final_analysis(analysis_results)
                analysis_results["final_analysis"] = final_analysis
                break
                
            elif "NEED_MORE_INFO" in decision_text:
                logger.info(f"LLMè¡¨ç¤ºéœ€è¦æ›´å¤šä¿¡æ¯: {decision_text}")
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å¤„ç†é€»è¾‘
                
            else:
                logger.warning(f"æ— æ³•è§£æLLMå†³ç­–: {decision_text}")
                break
        
        return analysis_results
    
    def _parse_tool_call_decision(self, decision_text: str) -> Optional[Dict[str, Any]]:
        """è§£æLLMçš„å·¥å…·è°ƒç”¨å†³ç­–"""
        try:
            lines = decision_text.split('\n')
            tool_name = None
            arguments = {}
            reason = ""
            
            for line in lines:
                line = line.strip()
                if line.startswith('å·¥å…·åç§°:'):
                    tool_name = line.split(':', 1)[1].strip()
                elif line.startswith('å‚æ•°:'):
                    param_str = line.split(':', 1)[1].strip()
                    try:
                        # å°è¯•è§£æJSONæ ¼å¼çš„å‚æ•°
                        if param_str.startswith('{') and param_str.endswith('}'):
                            arguments = json.loads(param_str)
                        else:
                            # å¦‚æœä¸æ˜¯JSONæ ¼å¼ï¼Œå°è¯•ç®€å•è§£æ
                            arguments = {"query": param_str}
                    except json.JSONDecodeError:
                        arguments = {"query": param_str}
                elif line.startswith('åŸå› :'):
                    reason = line.split(':', 1)[1].strip()
            
            if tool_name:
                return {
                    "tool_name": tool_name,
                    "arguments": arguments,
                    "reason": reason
                }
            
        except Exception as e:
            logger.error(f"è§£æå·¥å…·è°ƒç”¨å†³ç­–å¤±è´¥: {e}")
        
        return None
    
    def _update_analysis_data(self, analysis_results: Dict[str, Any], 
                             tool_name: str, result: Dict[str, Any]):
        """æ ¹æ®å·¥å…·è°ƒç”¨ç»“æœæ›´æ–°åˆ†ææ•°æ®"""
        if tool_name == "maps_geo":
            # åœ°ç†ç¼–ç ç»“æœ
            coords, city = self._extract_coordinates_and_city(result)
            if coords:
                if "work_location1" not in analysis_results["coordinates"]:
                    analysis_results["coordinates"]["work_location1"] = coords
                    analysis_results["coordinates"]["city1"] = city
                elif "work_location2" not in analysis_results["coordinates"]:
                    analysis_results["coordinates"]["work_location2"] = coords
                    analysis_results["coordinates"]["city2"] = city
                
        elif tool_name in ["maps_direction_transit_integrated", "maps_direction_walking"]:
            # è·¯çº¿ä¿¡æ¯
            if "routes" not in analysis_results["analysis_data"]:
                analysis_results["analysis_data"]["routes"] = []
            analysis_results["analysis_data"]["routes"].append(result)
            
        elif tool_name == "maps_around_search":
            # å‘¨è¾¹æœç´¢ç»“æœ
            if "poi_data" not in analysis_results["analysis_data"]:
                analysis_results["analysis_data"]["poi_data"] = []
            analysis_results["analysis_data"]["poi_data"].append(result)
            
        elif tool_name == "maps_text_search":
            # æ–‡æœ¬æœç´¢ç»“æœ
            if "search_results" not in analysis_results["analysis_data"]:
                analysis_results["analysis_data"]["search_results"] = []
            analysis_results["analysis_data"]["search_results"].append(result)
    
    def _extract_coordinates_and_city(self, geocode_result: Dict[str, Any]) -> tuple[Optional[str], Optional[str]]:
        """ä»åœ°ç†ç¼–ç ç»“æœä¸­æå–åæ ‡å’ŒåŸå¸‚ä¿¡æ¯"""
        try:
            if isinstance(geocode_result, dict):
                if "result" in geocode_result:
                    result_data = geocode_result["result"]
                    if "content" in result_data and isinstance(result_data["content"], list):
                        content = result_data["content"]
                        if len(content) > 0 and "text" in content[0]:
                            text_content = content[0]["text"]
                            parsed_data = json.loads(text_content)
                            if "results" in parsed_data and parsed_data["results"]:
                                first_result = parsed_data["results"][0]
                                location = first_result.get("location")
                                city = first_result.get("city", "").replace("å¸‚", "")
                                province = first_result.get("province", "").replace("å¸‚", "")
                                detected_city = city if city else province
                                return location, detected_city
            return None, None
        except Exception as e:
            logger.error(f"æå–åæ ‡å¤±è´¥: {e}")
            return None, None
    
    def _generate_current_status(self, analysis_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆå½“å‰åˆ†æçŠ¶æ€çš„æè¿°"""
        status_parts = []
        
        # åŸºæœ¬ä¿¡æ¯
        status_parts.append(f"ç›®æ ‡: ä¸ºç”¨æˆ·æ‰¾åˆ°è¿æ¥'{analysis_results['work_address1']}'å’Œ'{analysis_results['work_address2']}'çš„æœ€ä½³ç§Ÿæˆ¿ä½ç½®")
        
        # åæ ‡ä¿¡æ¯
        coords = analysis_results["coordinates"]
        if coords:
            status_parts.append(f"å·²è·å–åæ ‡: {len(coords)}ä¸ªä½ç½®")
            for key, value in coords.items():
                if key.startswith("work_location"):
                    status_parts.append(f"  - {key}: {value}")
        else:
            status_parts.append("å°šæœªè·å–å·¥ä½œåœ°ç‚¹åæ ‡")
        
        # å·¥å…·è°ƒç”¨ç»Ÿè®¡
        tool_calls = analysis_results["tool_calls"]
        if tool_calls:
            status_parts.append(f"å·²æ‰§è¡Œå·¥å…·è°ƒç”¨: {len(tool_calls)}æ¬¡")
            tool_summary = {}
            for call in tool_calls:
                tool_name = call["tool_name"]
                tool_summary[tool_name] = tool_summary.get(tool_name, 0) + 1
            for tool_name, count in tool_summary.items():
                status_parts.append(f"  - {tool_name}: {count}æ¬¡")
        else:
            status_parts.append("å°šæœªæ‰§è¡Œä»»ä½•å·¥å…·è°ƒç”¨")
        
        # åˆ†ææ•°æ®ç»Ÿè®¡
        analysis_data = analysis_results["analysis_data"]
        if analysis_data:
            status_parts.append("å·²æ”¶é›†çš„æ•°æ®ç±»å‹:")
            for data_type, data in analysis_data.items():
                if isinstance(data, list):
                    status_parts.append(f"  - {data_type}: {len(data)}æ¡è®°å½•")
                else:
                    status_parts.append(f"  - {data_type}: å·²æ”¶é›†")
        
        return "\n".join(status_parts)
    
    def _format_tool_calls_history(self, tool_calls: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å·¥å…·è°ƒç”¨å†å²"""
        if not tool_calls:
            return "æ— "
        
        formatted = []
        for i, call in enumerate(tool_calls, 1):
            formatted.append(f"{i}. {call['tool_name']}")
            formatted.append(f"   å‚æ•°: {call['arguments']}")
            formatted.append(f"   åŸå› : {call.get('reason', 'æœªè¯´æ˜')}")
            if 'error' in call:
                formatted.append(f"   ç»“æœ: å¤±è´¥ - {call['error']}")
            else:
                formatted.append(f"   ç»“æœ: æˆåŠŸ")
        
        return "\n".join(formatted)
    
    async def _generate_final_analysis(self, analysis_results: Dict[str, Any]) -> str:
        """ç”Ÿæˆæœ€ç»ˆçš„ç§Ÿæˆ¿åˆ†ææŠ¥å‘Š"""
        
        # æ„å»ºè¯¦ç»†çš„æ•°æ®æ€»ç»“ç»™LLM
        data_summary = self._build_data_summary_for_llm(analysis_results)
        
        final_prompt = f"""
        åŸºäºæ”¶é›†åˆ°çš„æ‰€æœ‰æ•°æ®ï¼Œè¯·ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„ç§Ÿæˆ¿ä½ç½®åˆ†ææŠ¥å‘Šã€‚

        **ç”¨æˆ·éœ€æ±‚å›é¡¾ï¼š**
        - å·¥ä½œåœ°ç‚¹A: {analysis_results['work_address1']}
        - å·¥ä½œåœ°ç‚¹B: {analysis_results['work_address2']}
        - é¢„ç®—èŒƒå›´: {analysis_results['budget_range']}
        - ç‰¹æ®Šåå¥½: {analysis_results['preferences']}

        **æ”¶é›†åˆ°çš„æ•°æ®ï¼š**
        {data_summary}

        è¯·ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„ç§Ÿæˆ¿å»ºè®®æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š

        ## ğŸ  æ¨èç§Ÿæˆ¿åŒºåŸŸ (è‡³å°‘3ä¸ª)

        ### ğŸŒŸ æ¨èåŒºåŸŸ1: [å…·ä½“åŒºåŸŸåç§°]
        **æ¨èç†ç”±ï¼š** [åŸºäºæ•°æ®åˆ†æçš„æ¨èç†ç”±]
        **åŒºåŸŸç‰¹ç‚¹ï¼š** [åŒºåŸŸç¯å¢ƒæè¿°]
        **é¢„ä¼°ç§Ÿé‡‘ï¼š** [ç§Ÿé‡‘èŒƒå›´]
        **ç”Ÿæ´»ä¾¿åˆ©åº¦ï¼š** â­â­â­â­â­

        #### ğŸš‡ é€šå‹¤åˆ†æ
        - **åˆ°å·¥ä½œåœ°ç‚¹A**: [å…·ä½“è·¯çº¿å’Œæ—¶é—´]
        - **åˆ°å·¥ä½œåœ°ç‚¹B**: [å…·ä½“è·¯çº¿å’Œæ—¶é—´]

        #### ğŸ˜ï¸ å‘¨è¾¹è®¾æ–½
        [åŸºäºæ”¶é›†çš„POIæ•°æ®åˆ†æå‘¨è¾¹è®¾æ–½]

        ### ğŸŒŸ æ¨èåŒºåŸŸ2: [ç¬¬äºŒä¸ªåŒºåŸŸ]
        [ç±»ä¼¼ç»“æ„]

        ### ğŸŒŸ æ¨èåŒºåŸŸ3: [ç¬¬ä¸‰ä¸ªåŒºåŸŸ]
        [ç±»ä¼¼ç»“æ„]

        ## ğŸ“Š ç»¼åˆåˆ†æ

        ### ğŸ¯ æœ€ä½³é€‰æ‹©
        [æ ¹æ®é€šå‹¤ä¾¿åˆ©æ€§ã€ç”Ÿæ´»ä¾¿åˆ©æ€§ã€ç»æµæ€§ç­‰å› ç´ ç»¼åˆè¯„ä¼°]

        ### ğŸ’¡ é€‰æˆ¿å»ºè®®
        [åŸºäºåˆ†ææ•°æ®çš„å®ç”¨å»ºè®®]

        ### âš ï¸ æ³¨æ„äº‹é¡¹
        [éœ€è¦æ³¨æ„çš„é—®é¢˜å’Œé£é™©]

        è¯·ç¡®ä¿æ‰€æœ‰å»ºè®®éƒ½åŸºäºå®é™…æ”¶é›†åˆ°çš„åœ°å›¾æ•°æ®ï¼Œæä¾›å…·ä½“ä¸”å®ç”¨çš„ä¿¡æ¯ã€‚
        """
        
        try:
            response = self.model.generate_content(final_prompt)
            return response.text
        except Exception as e:
            logger.error(f"ç”Ÿæˆæœ€ç»ˆåˆ†ææŠ¥å‘Šå¤±è´¥: {e}")
            return f"åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
    
    def _build_data_summary_for_llm(self, analysis_results: Dict[str, Any]) -> str:
        """ä¸ºLLMæ„å»ºæ•°æ®æ€»ç»“"""
        summary_parts = []
        
        # åæ ‡ä¿¡æ¯
        coords = analysis_results["coordinates"]
        if coords:
            summary_parts.append("**åæ ‡ä¿¡æ¯:**")
            for key, value in coords.items():
                summary_parts.append(f"- {key}: {value}")
        
        # å·¥å…·è°ƒç”¨ç»“æœ
        tool_calls = analysis_results["tool_calls"]
        if tool_calls:
            summary_parts.append("\n**å·¥å…·è°ƒç”¨ç»“æœ:**")
            for call in tool_calls:
                summary_parts.append(f"- {call['tool_name']}: {call.get('reason', 'æ•°æ®æ”¶é›†')}")
                if 'result' in call and not call.get('error'):
                    # ç®€åŒ–ç»“æœæ˜¾ç¤º
                    result_summary = self._summarize_tool_result(call['tool_name'], call['result'])
                    summary_parts.append(f"  ç»“æœ: {result_summary}")
        
        # åˆ†ææ•°æ®
        analysis_data = analysis_results["analysis_data"]
        if analysis_data:
            summary_parts.append("\n**æ”¶é›†çš„åˆ†ææ•°æ®:**")
            for data_type, data in analysis_data.items():
                summary_parts.append(f"- {data_type}: {self._summarize_data_type(data_type, data)}")
        
        return "\n".join(summary_parts)
    
    def _summarize_tool_result(self, tool_name: str, result: Dict[str, Any]) -> str:
        """æ€»ç»“å·¥å…·è°ƒç”¨ç»“æœ"""
        try:
            if tool_name == "maps_geo":
                coords, city = self._extract_coordinates_and_city(result)
                return f"åæ ‡: {coords}, åŸå¸‚: {city}"
            elif "direction" in tool_name:
                return "è·¯çº¿ä¿¡æ¯å·²è·å–"
            elif "search" in tool_name:
                return "æœç´¢ç»“æœå·²è·å–"
            else:
                return "æ•°æ®å·²æ”¶é›†"
        except:
            return "å·²å¤„ç†"
    
    def _summarize_data_type(self, data_type: str, data: Any) -> str:
        """æ€»ç»“æ•°æ®ç±»å‹"""
        if isinstance(data, list):
            return f"{len(data)}æ¡è®°å½•"
        else:
            return "å·²æ”¶é›†"

# ä½¿ç”¨ç¤ºä¾‹
async def example_usage():
    """ä½¿ç”¨ç¤ºä¾‹"""
    analyzer = IntelligentRentalAnalyzer()
    
    # æµ‹è¯•åˆ†æ
    result = await analyzer.analyze_rental_locations(
        work_address1="åŒ—äº¬å¸‚æµ·æ·€åŒºä¸­å…³æ‘å¤§è¡—1å·",
        work_address2="åŒ—äº¬å¸‚æœé˜³åŒºå›½è´¸CBD",
        budget_range="5000-8000å…ƒ",
        preferences="é è¿‘åœ°é“ï¼Œç¯å¢ƒå®‰é™"
    )
    
    print("æ™ºèƒ½åˆ†æç»“æœ:")
    print(json.dumps(result, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    asyncio.run(example_usage())
